{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT0qo6Mi6Hx6",
        "outputId": "746141c3-0ea5-436a-d1b3-a40b93f8f761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path= '/content/drive/MyDrive/train/'"
      ],
      "metadata": {
        "id": "2ECWGJZy8r48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "real_images= os.listdir(path)[0:200]"
      ],
      "metadata": {
        "id": "V-4vxk7j89hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(real_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISmf3yHB-cOU",
        "outputId": "afde1936-7b67-441c-8ffc-07b8047a13a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define image size\n",
        "image_size = (64, 64)\n",
        "\n",
        "preprocessed_images = []\n",
        "\n",
        "# Load and preprocess images\n",
        "for image_file in real_images :\n",
        "    # Load image\n",
        "    image = cv2.imread(path+\n",
        "    image_file)\n",
        "\n",
        "    # Resize image\n",
        "    image = cv2.resize(image, image_size)\n",
        "\n",
        "    # Normalize pixel values\n",
        "    image = image / 255.0\n",
        "    image = image - 0.5\n",
        "    image = image * 2.0\n",
        "\n",
        "    # Add image to the list\n",
        "    preprocessed_images.append(image)\n",
        "\n",
        "# Convert the list to a NumPy array\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "flattened_images=preprocessed_images.reshape(-1, 12288)\n"
      ],
      "metadata": {
        "id": "FWBg9rvU9I-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2qQDZOJDRwM",
        "outputId": "d1c0606d-cae2-4dce-cf95-410aeada34c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 0.70196078,  0.84313725,  0.70980392],\n",
              "         [ 0.51372549,  0.70980392,  0.60784314],\n",
              "         [ 0.49019608,  0.70196078,  0.63137255],\n",
              "         ...,\n",
              "         [-0.23137255, -0.06666667, -0.05098039],\n",
              "         [-0.34117647, -0.20784314, -0.18431373],\n",
              "         [-0.58431373, -0.43529412, -0.48235294]],\n",
              "\n",
              "        [[ 0.61568627,  0.75686275,  0.62352941],\n",
              "         [ 0.52156863,  0.7254902 ,  0.61568627],\n",
              "         [ 0.52941176,  0.74117647,  0.67058824],\n",
              "         ...,\n",
              "         [-0.44313725, -0.23137255, -0.22352941],\n",
              "         [-0.46666667, -0.28627451, -0.27058824],\n",
              "         [-0.41960784, -0.23921569, -0.25490196]],\n",
              "\n",
              "        [[ 0.46666667,  0.64705882,  0.58431373],\n",
              "         [ 0.51372549,  0.69411765,  0.63137255],\n",
              "         [ 0.52156863,  0.73333333,  0.65490196],\n",
              "         ...,\n",
              "         [-0.55294118, -0.36470588, -0.38039216],\n",
              "         [-0.4745098 , -0.28627451, -0.30196078],\n",
              "         [-0.48235294, -0.27843137, -0.30980392]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.09019608,  0.0745098 ,  0.02745098],\n",
              "         [-0.09019608,  0.06666667,  0.02745098],\n",
              "         [ 0.00392157,  0.17647059,  0.12941176],\n",
              "         ...,\n",
              "         [-0.09803922,  0.08235294,  0.04313725],\n",
              "         [-0.0745098 ,  0.10588235,  0.05882353],\n",
              "         [-0.02745098,  0.1372549 ,  0.0745098 ]],\n",
              "\n",
              "        [[-0.0745098 ,  0.08235294,  0.04313725],\n",
              "         [-0.04313725,  0.11372549,  0.0745098 ],\n",
              "         [-0.06666667,  0.11372549,  0.06666667],\n",
              "         ...,\n",
              "         [-0.0745098 ,  0.09803922,  0.05882353],\n",
              "         [-0.1372549 ,  0.03529412, -0.00392157],\n",
              "         [-0.00392157,  0.15294118,  0.10588235]],\n",
              "\n",
              "        [[-0.08235294,  0.09803922,  0.05882353],\n",
              "         [-0.09019608,  0.0745098 ,  0.04313725],\n",
              "         [-0.14509804,  0.01960784, -0.00392157],\n",
              "         ...,\n",
              "         [ 0.01176471,  0.16078431,  0.12156863],\n",
              "         [-0.01176471,  0.15294118,  0.11372549],\n",
              "         [-0.05882353,  0.09803922,  0.08235294]]],\n",
              "\n",
              "\n",
              "       [[[ 0.56078431,  0.61568627,  0.86666667],\n",
              "         [ 0.63921569,  0.6627451 ,  0.88235294],\n",
              "         [ 0.63921569,  0.67843137,  0.8745098 ],\n",
              "         ...,\n",
              "         [-0.46666667,  0.0745098 , -0.40392157],\n",
              "         [-0.41176471,  0.06666667, -0.16862745],\n",
              "         [-0.69411765, -0.16862745, -0.5372549 ]],\n",
              "\n",
              "        [[ 0.56862745,  0.62352941,  0.8745098 ],\n",
              "         [ 0.63921569,  0.6627451 ,  0.8745098 ],\n",
              "         [ 0.62352941,  0.6627451 ,  0.85882353],\n",
              "         ...,\n",
              "         [-0.54509804, -0.03529412, -0.5372549 ],\n",
              "         [-0.82745098, -0.31764706, -0.68627451],\n",
              "         [-0.96078431, -0.38039216, -0.81176471]],\n",
              "\n",
              "        [[ 0.59215686,  0.64705882,  0.89803922],\n",
              "         [ 0.63921569,  0.6627451 ,  0.8745098 ],\n",
              "         [ 0.57647059,  0.61568627,  0.81176471],\n",
              "         ...,\n",
              "         [-0.69411765, -0.2627451 , -0.63921569],\n",
              "         [-0.55294118, -0.06666667, -0.45882353],\n",
              "         [-0.80392157, -0.27843137, -0.6627451 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.03529412,  0.0745098 , -0.2       ],\n",
              "         [ 0.01960784,  0.12156863, -0.12941176],\n",
              "         [-0.11372549, -0.01960784, -0.23921569],\n",
              "         ...,\n",
              "         [-0.60784314, -0.21568627, -0.50588235],\n",
              "         [-0.78039216, -0.25490196, -0.63137255],\n",
              "         [-0.78823529, -0.45882353, -0.68627451]],\n",
              "\n",
              "        [[-0.12156863, -0.03529412, -0.23921569],\n",
              "         [ 0.00392157,  0.10588235, -0.14509804],\n",
              "         [-0.05098039,  0.06666667, -0.17647059],\n",
              "         ...,\n",
              "         [-0.89803922, -0.41176471, -0.71764706],\n",
              "         [-0.54509804, -0.09803922, -0.43529412],\n",
              "         [-0.5372549 , -0.04313725, -0.38823529]],\n",
              "\n",
              "        [[-0.05098039,  0.04313725, -0.19215686],\n",
              "         [-0.03529412,  0.05882353, -0.16078431],\n",
              "         [-0.00392157,  0.11372549, -0.12941176],\n",
              "         ...,\n",
              "         [-0.79607843, -0.33333333, -0.67843137],\n",
              "         [-0.77254902, -0.38039216, -0.65490196],\n",
              "         [-0.57647059, -0.09019608, -0.43529412]]],\n",
              "\n",
              "\n",
              "       [[[-0.27058824, -0.23921569, -0.28627451],\n",
              "         [-0.34901961, -0.31764706, -0.36470588],\n",
              "         [-0.31764706, -0.28627451, -0.33333333],\n",
              "         ...,\n",
              "         [-0.42745098, -0.35686275, -0.4745098 ],\n",
              "         [-0.59215686, -0.59215686, -0.60784314],\n",
              "         [ 0.3254902 ,  0.30196078,  0.08235294]],\n",
              "\n",
              "        [[-0.4745098 , -0.40392157, -0.42745098],\n",
              "         [-0.45098039, -0.37254902, -0.39607843],\n",
              "         [-0.45882353, -0.38039216, -0.41176471],\n",
              "         ...,\n",
              "         [-0.70196078, -0.63137255, -0.75686275],\n",
              "         [-0.70196078, -0.70980392, -0.71764706],\n",
              "         [ 0.17647059,  0.16862745, -0.05098039]],\n",
              "\n",
              "        [[-0.42745098, -0.30196078, -0.30196078],\n",
              "         [-0.43529412, -0.30980392, -0.31764706],\n",
              "         [-0.49803922, -0.37254902, -0.38039216],\n",
              "         ...,\n",
              "         [-0.69411765, -0.61568627, -0.74117647],\n",
              "         [-0.74117647, -0.74117647, -0.75686275],\n",
              "         [ 0.01960784,  0.05882353, -0.22352941]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.1372549 ,  0.01960784, -0.05098039],\n",
              "         [ 0.30196078,  0.23137255,  0.12941176],\n",
              "         [ 0.12156863,  0.08235294, -0.02745098],\n",
              "         ...,\n",
              "         [-0.17647059, -0.25490196, -0.33333333],\n",
              "         [-0.19215686, -0.25490196, -0.29411765],\n",
              "         [-0.28627451, -0.34901961, -0.37254902]],\n",
              "\n",
              "        [[-0.01960784, -0.10588235, -0.19215686],\n",
              "         [-0.21568627, -0.21568627, -0.2627451 ],\n",
              "         [-0.06666667, -0.0745098 , -0.18431373],\n",
              "         ...,\n",
              "         [-0.62352941, -0.63137255, -0.70980392],\n",
              "         [-0.15294118, -0.23137255, -0.2627451 ],\n",
              "         [-0.2       , -0.29411765, -0.3254902 ]],\n",
              "\n",
              "        [[-0.2       , -0.19215686, -0.27843137],\n",
              "         [-0.15294118, -0.21568627, -0.28627451],\n",
              "         [-0.31764706, -0.46666667, -0.63137255],\n",
              "         ...,\n",
              "         [-0.30980392, -0.35686275, -0.41176471],\n",
              "         [-0.49803922, -0.5372549 , -0.60784314],\n",
              "         [-0.16862745, -0.21568627, -0.27843137]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 0.89019608,  0.94509804,  0.84313725],\n",
              "         [ 0.82745098,  0.86666667,  0.78823529],\n",
              "         [ 0.85882353,  0.89019608,  0.84313725],\n",
              "         ...,\n",
              "         [ 0.85882353,  0.89019608,  0.84313725],\n",
              "         [ 0.90588235,  0.9372549 ,  0.89019608],\n",
              "         [ 0.84313725,  0.89019608,  0.85098039]],\n",
              "\n",
              "        [[ 0.8745098 ,  0.92156863,  0.83529412],\n",
              "         [-0.45882353, -0.41960784, -0.49019608],\n",
              "         [-0.44313725, -0.41176471, -0.45882353],\n",
              "         ...,\n",
              "         [-0.38039216, -0.34901961, -0.38823529],\n",
              "         [-0.50588235, -0.4745098 , -0.51372549],\n",
              "         [ 0.84313725,  0.89019608,  0.85098039]],\n",
              "\n",
              "        [[ 0.83529412,  0.8745098 ,  0.80392157],\n",
              "         [-0.78039216, -0.74901961, -0.79607843],\n",
              "         [ 0.89019608,  0.91372549,  0.89803922],\n",
              "         ...,\n",
              "         [ 0.85098039,  0.8745098 ,  0.85882353],\n",
              "         [-0.73333333, -0.70980392, -0.7254902 ],\n",
              "         [ 0.84313725,  0.89019608,  0.85098039]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.88235294,  0.90588235,  0.89019608],\n",
              "         [-0.60784314, -0.58431373, -0.60784314],\n",
              "         [ 0.85882353,  0.88235294,  0.86666667],\n",
              "         ...,\n",
              "         [ 0.92156863,  0.9372549 ,  0.92941176],\n",
              "         [-0.74117647, -0.71764706, -0.73333333],\n",
              "         [ 0.84313725,  0.89019608,  0.85098039]],\n",
              "\n",
              "        [[ 0.85882353,  0.88235294,  0.86666667],\n",
              "         [-0.52156863, -0.50588235, -0.51372549],\n",
              "         [-0.45098039, -0.42745098, -0.44313725],\n",
              "         ...,\n",
              "         [-0.35686275, -0.33333333, -0.34901961],\n",
              "         [-0.42745098, -0.40392157, -0.41960784],\n",
              "         [ 0.84313725,  0.89019608,  0.85098039]],\n",
              "\n",
              "        [[ 0.82745098,  0.86666667,  0.83529412],\n",
              "         [ 0.82745098,  0.86666667,  0.83529412],\n",
              "         [ 0.84313725,  0.88235294,  0.85098039],\n",
              "         ...,\n",
              "         [ 0.85098039,  0.89019608,  0.85882353],\n",
              "         [ 0.85098039,  0.89019608,  0.85882353],\n",
              "         [ 0.84313725,  0.89019608,  0.85098039]]],\n",
              "\n",
              "\n",
              "       [[[-0.70980392, -0.63921569, -0.60784314],\n",
              "         [-0.60784314, -0.5372549 , -0.50588235],\n",
              "         [-0.81960784, -0.74901961, -0.70196078],\n",
              "         ...,\n",
              "         [-0.16078431, -0.0745098 , -0.09019608],\n",
              "         [-0.44313725, -0.41960784, -0.41960784],\n",
              "         [-0.19215686, -0.21568627, -0.20784314]],\n",
              "\n",
              "        [[-0.25490196, -0.18431373, -0.15294118],\n",
              "         [-0.74901961, -0.67843137, -0.64705882],\n",
              "         [-0.55294118, -0.52941176, -0.46666667],\n",
              "         ...,\n",
              "         [-0.39607843, -0.38823529, -0.38823529],\n",
              "         [ 0.02745098,  0.01176471,  0.01176471],\n",
              "         [-0.45098039, -0.46666667, -0.46666667]],\n",
              "\n",
              "        [[-0.41960784, -0.34117647, -0.30980392],\n",
              "         [-0.34117647, -0.27058824, -0.23921569],\n",
              "         [-0.42745098, -0.41960784, -0.34901961],\n",
              "         ...,\n",
              "         [-0.12941176, -0.15294118, -0.12941176],\n",
              "         [-0.43529412, -0.46666667, -0.45882353],\n",
              "         [-0.49803922, -0.49803922, -0.49803922]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.51372549, -0.67058824, -0.50588235],\n",
              "         [-0.44313725, -0.6627451 , -0.48235294],\n",
              "         [-0.42745098, -0.65490196, -0.4745098 ],\n",
              "         ...,\n",
              "         [ 0.27843137,  0.70980392,  0.95294118],\n",
              "         [ 0.27843137,  0.7254902 ,  0.96862745],\n",
              "         [ 0.31764706,  0.71764706,  0.96862745]],\n",
              "\n",
              "        [[-0.52941176, -0.75686275, -0.56862745],\n",
              "         [-0.46666667, -0.68627451, -0.50588235],\n",
              "         [-0.41176471, -0.67843137, -0.49803922],\n",
              "         ...,\n",
              "         [ 0.27843137,  0.74117647,  0.97647059],\n",
              "         [ 0.27843137,  0.7254902 ,  0.96862745],\n",
              "         [ 0.27843137,  0.69411765,  0.95294118]],\n",
              "\n",
              "        [[-0.52941176, -0.73333333, -0.55294118],\n",
              "         [-0.51372549, -0.71764706, -0.5372549 ],\n",
              "         [-0.41176471, -0.63137255, -0.45098039],\n",
              "         ...,\n",
              "         [ 0.27058824,  0.73333333,  0.98431373],\n",
              "         [ 0.27843137,  0.70980392,  0.96078431],\n",
              "         [ 0.24705882,  0.63921569,  0.90588235]]],\n",
              "\n",
              "\n",
              "       [[[ 0.03529412,  0.16078431,  0.20784314],\n",
              "         [ 0.02745098,  0.15294118,  0.2       ],\n",
              "         [ 0.01176471,  0.1372549 ,  0.18431373],\n",
              "         ...,\n",
              "         [ 0.42745098,  0.44313725,  0.45098039],\n",
              "         [ 0.42745098,  0.44313725,  0.44313725],\n",
              "         [ 0.42745098,  0.44313725,  0.44313725]],\n",
              "\n",
              "        [[ 0.03529412,  0.16078431,  0.20784314],\n",
              "         [ 0.02745098,  0.15294118,  0.2       ],\n",
              "         [ 0.01176471,  0.1372549 ,  0.18431373],\n",
              "         ...,\n",
              "         [ 0.42745098,  0.44313725,  0.45098039],\n",
              "         [ 0.42745098,  0.44313725,  0.44313725],\n",
              "         [ 0.42745098,  0.44313725,  0.44313725]],\n",
              "\n",
              "        [[ 0.04313725,  0.16078431,  0.2       ],\n",
              "         [ 0.02745098,  0.15294118,  0.19215686],\n",
              "         [ 0.01960784,  0.14509804,  0.18431373],\n",
              "         ...,\n",
              "         [ 0.42745098,  0.44313725,  0.45098039],\n",
              "         [ 0.42745098,  0.44313725,  0.44313725],\n",
              "         [ 0.42745098,  0.44313725,  0.44313725]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.38039216,  0.36470588,  0.37254902],\n",
              "         [ 0.35686275,  0.34901961,  0.35686275],\n",
              "         [ 0.38823529,  0.38039216,  0.38039216],\n",
              "         ...,\n",
              "         [ 0.12941176,  0.18431373,  0.15294118],\n",
              "         [ 0.08235294,  0.12156863,  0.12156863],\n",
              "         [-0.01176471,  0.04313725,  0.02745098]],\n",
              "\n",
              "        [[ 0.23921569,  0.23921569,  0.23921569],\n",
              "         [ 0.27843137,  0.27843137,  0.27843137],\n",
              "         [ 0.31764706,  0.31764706,  0.31764706],\n",
              "         ...,\n",
              "         [ 0.0745098 ,  0.12941176,  0.10588235],\n",
              "         [ 0.08235294,  0.12941176,  0.11372549],\n",
              "         [ 0.06666667,  0.11372549,  0.10588235]],\n",
              "\n",
              "        [[ 0.15294118,  0.15294118,  0.15294118],\n",
              "         [ 0.14509804,  0.14509804,  0.14509804],\n",
              "         [ 0.2       ,  0.2       ,  0.2       ],\n",
              "         ...,\n",
              "         [ 0.09019608,  0.12941176,  0.11372549],\n",
              "         [ 0.09019608,  0.09019608,  0.09019608],\n",
              "         [ 0.11372549,  0.12941176,  0.12941176]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSe_l6NklqLU",
        "outputId": "a1d878b9-ab88-4047-d896-3cc8ed3de508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 423ms/step\n",
            "Epoch: 1/100, Batch: 0/6, Discriminator Loss: 0.7483454346656799, Generator Loss: 0.6233937740325928\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 1/100, Batch: 1/6, Discriminator Loss: 1.501020594201691, Generator Loss: 0.383856862783432\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "Epoch: 1/100, Batch: 2/6, Discriminator Loss: 2.2609713580750395, Generator Loss: 3.192168712615967\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Epoch: 1/100, Batch: 3/6, Discriminator Loss: 0.14801340596750379, Generator Loss: 4.41839599609375\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 1/100, Batch: 4/6, Discriminator Loss: 0.19897151898476295, Generator Loss: 2.947807788848877\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 1/100, Batch: 5/6, Discriminator Loss: 0.318275740952231, Generator Loss: 2.1355016231536865\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "Epoch: 2/100, Batch: 0/6, Discriminator Loss: 0.21626107627525926, Generator Loss: 1.9438209533691406\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 2/100, Batch: 1/6, Discriminator Loss: 0.273909455165267, Generator Loss: 1.2318933010101318\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 2/100, Batch: 2/6, Discriminator Loss: 0.3574252611215343, Generator Loss: 0.8092544078826904\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 2/100, Batch: 3/6, Discriminator Loss: 0.3419693207688397, Generator Loss: 0.8370842337608337\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 2/100, Batch: 4/6, Discriminator Loss: 0.40288539230823517, Generator Loss: 0.8113356828689575\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 2/100, Batch: 5/6, Discriminator Loss: 0.3113576531764011, Generator Loss: 0.8100019693374634\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 3/100, Batch: 0/6, Discriminator Loss: 0.3038470563273741, Generator Loss: 0.8194624185562134\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 3/100, Batch: 1/6, Discriminator Loss: 0.3121788156568073, Generator Loss: 0.8165751099586487\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 3/100, Batch: 2/6, Discriminator Loss: 0.37080456043186416, Generator Loss: 0.7771435379981995\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 3/100, Batch: 3/6, Discriminator Loss: 0.41586202871070554, Generator Loss: 0.8248791098594666\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 3/100, Batch: 4/6, Discriminator Loss: 0.28401124817855816, Generator Loss: 1.0404512882232666\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 3/100, Batch: 5/6, Discriminator Loss: 0.38127725571393967, Generator Loss: 0.8365039229393005\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "Epoch: 4/100, Batch: 0/6, Discriminator Loss: 0.291520695993313, Generator Loss: 0.8560057282447815\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 4/100, Batch: 1/6, Discriminator Loss: 0.28233748706831585, Generator Loss: 0.8940185308456421\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 4/100, Batch: 2/6, Discriminator Loss: 0.31123847092391865, Generator Loss: 0.9582475423812866\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Epoch: 4/100, Batch: 3/6, Discriminator Loss: 0.28405392844069866, Generator Loss: 1.0483359098434448\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 4/100, Batch: 4/6, Discriminator Loss: 0.23796401512211673, Generator Loss: 1.1596719026565552\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 4/100, Batch: 5/6, Discriminator Loss: 0.29149381423667364, Generator Loss: 1.3666887283325195\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 5/100, Batch: 0/6, Discriminator Loss: 0.6398664265871048, Generator Loss: 0.9589151740074158\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Epoch: 5/100, Batch: 1/6, Discriminator Loss: 0.5433259606361389, Generator Loss: 0.9493188858032227\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 5/100, Batch: 2/6, Discriminator Loss: 0.3701228201389313, Generator Loss: 0.9995994567871094\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 5/100, Batch: 3/6, Discriminator Loss: 0.24255956709384918, Generator Loss: 1.0750460624694824\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "Epoch: 5/100, Batch: 4/6, Discriminator Loss: 0.23855732381343842, Generator Loss: 1.0922572612762451\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 5/100, Batch: 5/6, Discriminator Loss: 2.3967227935791016, Generator Loss: 0.9032503366470337\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 6/100, Batch: 0/6, Discriminator Loss: 0.36341279745102867, Generator Loss: 1.7584254741668701\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 6/100, Batch: 1/6, Discriminator Loss: 0.7382954806089401, Generator Loss: 1.358490228652954\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 6/100, Batch: 2/6, Discriminator Loss: 0.2674820605079731, Generator Loss: 1.221771001815796\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Epoch: 6/100, Batch: 3/6, Discriminator Loss: 0.6651299223303795, Generator Loss: 0.8873884081840515\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 6/100, Batch: 4/6, Discriminator Loss: 0.7967818640172482, Generator Loss: 1.6952546834945679\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 6/100, Batch: 5/6, Discriminator Loss: 0.7875977754592896, Generator Loss: 0.8057358264923096\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "Epoch: 7/100, Batch: 0/6, Discriminator Loss: 0.3032026468810045, Generator Loss: 0.8395504355430603\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Epoch: 7/100, Batch: 1/6, Discriminator Loss: 0.3121141195354661, Generator Loss: 0.8588367700576782\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "Epoch: 7/100, Batch: 2/6, Discriminator Loss: 0.4488334579139064, Generator Loss: 0.9991068243980408\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 7/100, Batch: 3/6, Discriminator Loss: 0.4402648154818962, Generator Loss: 2.914292573928833\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 7/100, Batch: 4/6, Discriminator Loss: 1.047610193490982, Generator Loss: 0.9619022011756897\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 7/100, Batch: 5/6, Discriminator Loss: 0.36268510669469833, Generator Loss: 1.0112652778625488\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Epoch: 8/100, Batch: 0/6, Discriminator Loss: 0.24339565706068939, Generator Loss: 1.0733592510223389\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 8/100, Batch: 1/6, Discriminator Loss: 0.3383104206390823, Generator Loss: 0.9568315744400024\n",
            "1/1 [==============================] - 0s 207ms/step\n",
            "Epoch: 8/100, Batch: 2/6, Discriminator Loss: 2.102834224701547, Generator Loss: 1.4993274211883545\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 8/100, Batch: 3/6, Discriminator Loss: 0.1738967567216605, Generator Loss: 2.4430360794067383\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 8/100, Batch: 4/6, Discriminator Loss: 0.3227159082889557, Generator Loss: 1.1357744932174683\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Epoch: 8/100, Batch: 5/6, Discriminator Loss: 0.23244696929986636, Generator Loss: 1.1551340818405151\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 9/100, Batch: 0/6, Discriminator Loss: 0.3021506898800439, Generator Loss: 1.1265361309051514\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 9/100, Batch: 1/6, Discriminator Loss: 0.5502510084194913, Generator Loss: 1.3513705730438232\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 9/100, Batch: 2/6, Discriminator Loss: 0.1983447907232403, Generator Loss: 3.5165815353393555\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 9/100, Batch: 3/6, Discriminator Loss: 0.8002646267414093, Generator Loss: 0.980486273765564\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 9/100, Batch: 4/6, Discriminator Loss: 0.4423008868246748, Generator Loss: 0.7176330089569092\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 9/100, Batch: 5/6, Discriminator Loss: 0.5322608247624885, Generator Loss: 0.8676272630691528\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 10/100, Batch: 0/6, Discriminator Loss: 0.23972341301850975, Generator Loss: 2.523725986480713\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 10/100, Batch: 1/6, Discriminator Loss: 1.1274645030498505, Generator Loss: 0.9144706726074219\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 10/100, Batch: 2/6, Discriminator Loss: 0.25900748553794983, Generator Loss: 1.0586590766906738\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "Epoch: 10/100, Batch: 3/6, Discriminator Loss: 0.2490709357604146, Generator Loss: 1.1696646213531494\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 10/100, Batch: 4/6, Discriminator Loss: 0.7604411929905837, Generator Loss: 1.3397226333618164\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 10/100, Batch: 5/6, Discriminator Loss: 0.4447504337877035, Generator Loss: 5.109060287475586\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 11/100, Batch: 0/6, Discriminator Loss: 1.4235236644744873, Generator Loss: 1.0601212978363037\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 11/100, Batch: 1/6, Discriminator Loss: 0.20235313296871027, Generator Loss: 1.1881349086761475\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 11/100, Batch: 2/6, Discriminator Loss: 0.18493103254877497, Generator Loss: 1.2794430255889893\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 11/100, Batch: 3/6, Discriminator Loss: 0.26658607562285397, Generator Loss: 1.2326351404190063\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "Epoch: 11/100, Batch: 4/6, Discriminator Loss: 0.5122366021455376, Generator Loss: 2.063168525695801\n",
            "1/1 [==============================] - 0s 162ms/step\n",
            "Epoch: 11/100, Batch: 5/6, Discriminator Loss: 0.13655139710681397, Generator Loss: 1.784826397895813\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "Epoch: 12/100, Batch: 0/6, Discriminator Loss: 0.12312138816923834, Generator Loss: 1.6469554901123047\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 12/100, Batch: 1/6, Discriminator Loss: 0.4004626125097275, Generator Loss: 1.342111587524414\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 12/100, Batch: 2/6, Discriminator Loss: 0.25039044368168106, Generator Loss: 1.2876842021942139\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 12/100, Batch: 3/6, Discriminator Loss: 0.4556581073338748, Generator Loss: 1.5977041721343994\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 12/100, Batch: 4/6, Discriminator Loss: 0.16373983462403885, Generator Loss: 1.970017433166504\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 12/100, Batch: 5/6, Discriminator Loss: 0.12477688022045186, Generator Loss: 1.8066167831420898\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "Epoch: 13/100, Batch: 0/6, Discriminator Loss: 0.18785416148602962, Generator Loss: 1.7139389514923096\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 13/100, Batch: 1/6, Discriminator Loss: 0.15346977698709452, Generator Loss: 2.149951219558716\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 13/100, Batch: 2/6, Discriminator Loss: 0.20669249445199966, Generator Loss: 1.494786262512207\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 13/100, Batch: 3/6, Discriminator Loss: 0.21505890684420592, Generator Loss: 1.4019603729248047\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 13/100, Batch: 4/6, Discriminator Loss: 0.21388772808131762, Generator Loss: 1.611332654953003\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 13/100, Batch: 5/6, Discriminator Loss: 0.1603309808085669, Generator Loss: 2.7116689682006836\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 14/100, Batch: 0/6, Discriminator Loss: 0.1075360719114542, Generator Loss: 1.8464999198913574\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 14/100, Batch: 1/6, Discriminator Loss: 0.1539942323369985, Generator Loss: 1.9564332962036133\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Epoch: 14/100, Batch: 2/6, Discriminator Loss: 0.42583855986595154, Generator Loss: 1.5742943286895752\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "Epoch: 14/100, Batch: 3/6, Discriminator Loss: 0.2874631866402524, Generator Loss: 2.5093331336975098\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 14/100, Batch: 4/6, Discriminator Loss: 0.06159056842807331, Generator Loss: 2.7847115993499756\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 14/100, Batch: 5/6, Discriminator Loss: 0.09521608985960484, Generator Loss: 2.157078266143799\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 15/100, Batch: 0/6, Discriminator Loss: 0.26477909088134766, Generator Loss: 1.74543035030365\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 15/100, Batch: 1/6, Discriminator Loss: 0.27836805584698504, Generator Loss: 1.8462114334106445\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 15/100, Batch: 2/6, Discriminator Loss: 0.1814862764440477, Generator Loss: 3.4982659816741943\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 15/100, Batch: 3/6, Discriminator Loss: 0.23385368287563324, Generator Loss: 1.988234519958496\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 15/100, Batch: 4/6, Discriminator Loss: 0.13443952100351453, Generator Loss: 1.892273187637329\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 15/100, Batch: 5/6, Discriminator Loss: 0.1373947857989961, Generator Loss: 2.1490302085876465\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Epoch: 16/100, Batch: 0/6, Discriminator Loss: 0.16207822582420306, Generator Loss: 3.5913681983947754\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "Epoch: 16/100, Batch: 1/6, Discriminator Loss: 0.022702541878970806, Generator Loss: 3.4668452739715576\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 16/100, Batch: 2/6, Discriminator Loss: 0.6541732847690582, Generator Loss: 1.668915033340454\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 16/100, Batch: 3/6, Discriminator Loss: 0.25391379134682357, Generator Loss: 1.504216194152832\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 16/100, Batch: 4/6, Discriminator Loss: 0.34126091003702375, Generator Loss: 1.9544681310653687\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 16/100, Batch: 5/6, Discriminator Loss: 0.11260107280912024, Generator Loss: 2.4433488845825195\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 17/100, Batch: 0/6, Discriminator Loss: 0.14018435031175613, Generator Loss: 1.9397366046905518\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 17/100, Batch: 1/6, Discriminator Loss: 0.6751841367279687, Generator Loss: 1.5885494947433472\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 17/100, Batch: 2/6, Discriminator Loss: 1.4678203985095024, Generator Loss: 3.652256965637207\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "Epoch: 17/100, Batch: 3/6, Discriminator Loss: 0.10385447938460857, Generator Loss: 4.0926313400268555\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "Epoch: 17/100, Batch: 4/6, Discriminator Loss: 0.22360430657863617, Generator Loss: 1.8447210788726807\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 17/100, Batch: 5/6, Discriminator Loss: 0.10731628048233688, Generator Loss: 1.956984281539917\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 18/100, Batch: 0/6, Discriminator Loss: 0.14086690425756387, Generator Loss: 2.0103511810302734\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 18/100, Batch: 1/6, Discriminator Loss: 0.24784707091748714, Generator Loss: 3.5651063919067383\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 18/100, Batch: 2/6, Discriminator Loss: 0.08455108664929867, Generator Loss: 2.572841167449951\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 18/100, Batch: 3/6, Discriminator Loss: 0.07971596671268344, Generator Loss: 2.410386562347412\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 18/100, Batch: 4/6, Discriminator Loss: 0.057597509112383705, Generator Loss: 2.7840166091918945\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 18/100, Batch: 5/6, Discriminator Loss: 0.05180859154961581, Generator Loss: 2.6930947303771973\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 19/100, Batch: 0/6, Discriminator Loss: 0.1464465732840381, Generator Loss: 2.6450817584991455\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 19/100, Batch: 1/6, Discriminator Loss: 0.11306246314779855, Generator Loss: 4.078106880187988\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 19/100, Batch: 2/6, Discriminator Loss: 0.7122131511569023, Generator Loss: 2.031318187713623\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 19/100, Batch: 3/6, Discriminator Loss: 0.21748594837254132, Generator Loss: 1.7606148719787598\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 19/100, Batch: 4/6, Discriminator Loss: 0.25148022775829304, Generator Loss: 2.3889288902282715\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 19/100, Batch: 5/6, Discriminator Loss: 0.09321274342892139, Generator Loss: 4.295928001403809\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 20/100, Batch: 0/6, Discriminator Loss: 0.04536774195730686, Generator Loss: 3.2103919982910156\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 20/100, Batch: 1/6, Discriminator Loss: 0.4520619958639145, Generator Loss: 3.626087188720703\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 20/100, Batch: 2/6, Discriminator Loss: 0.1116204746067524, Generator Loss: 2.171571731567383\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 20/100, Batch: 3/6, Discriminator Loss: 0.15066033221955877, Generator Loss: 2.2873268127441406\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Epoch: 20/100, Batch: 4/6, Discriminator Loss: 0.061331437860644655, Generator Loss: 2.7653322219848633\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Epoch: 20/100, Batch: 5/6, Discriminator Loss: 0.11567155217926484, Generator Loss: 4.138958930969238\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "Epoch: 21/100, Batch: 0/6, Discriminator Loss: 0.016471176990307868, Generator Loss: 4.277433395385742\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 21/100, Batch: 1/6, Discriminator Loss: 0.7985098659992218, Generator Loss: 1.766095519065857\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 21/100, Batch: 2/6, Discriminator Loss: 0.648204617202282, Generator Loss: 2.7751739025115967\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 21/100, Batch: 3/6, Discriminator Loss: 0.043592375091975555, Generator Loss: 3.7522168159484863\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 21/100, Batch: 4/6, Discriminator Loss: 0.2598477452993393, Generator Loss: 1.9674608707427979\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 21/100, Batch: 5/6, Discriminator Loss: 0.19357682764530182, Generator Loss: 2.017667770385742\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 22/100, Batch: 0/6, Discriminator Loss: 0.12415875011009803, Generator Loss: 2.5521419048309326\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 22/100, Batch: 1/6, Discriminator Loss: 0.07068917341530323, Generator Loss: 3.406487464904785\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Epoch: 22/100, Batch: 2/6, Discriminator Loss: 0.16464674286544323, Generator Loss: 3.279629707336426\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "Epoch: 22/100, Batch: 3/6, Discriminator Loss: 0.03838963515590876, Generator Loss: 3.443209171295166\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 22/100, Batch: 4/6, Discriminator Loss: 0.39552445709705353, Generator Loss: 1.6444690227508545\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch: 22/100, Batch: 5/6, Discriminator Loss: 0.2108412476027013, Generator Loss: 2.5595297813415527\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 23/100, Batch: 0/6, Discriminator Loss: 0.026830817205336643, Generator Loss: 4.153899669647217\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 23/100, Batch: 1/6, Discriminator Loss: 0.3659973815083504, Generator Loss: 2.2563045024871826\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 23/100, Batch: 2/6, Discriminator Loss: 0.08275781851261854, Generator Loss: 2.181485652923584\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 23/100, Batch: 3/6, Discriminator Loss: 0.14812377883072259, Generator Loss: 2.5223827362060547\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 23/100, Batch: 4/6, Discriminator Loss: 0.046065221272783674, Generator Loss: 2.9573135375976562\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Epoch: 23/100, Batch: 5/6, Discriminator Loss: 0.03254616889171302, Generator Loss: 3.272545337677002\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "Epoch: 24/100, Batch: 0/6, Discriminator Loss: 0.026927783436860864, Generator Loss: 3.200627326965332\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 24/100, Batch: 1/6, Discriminator Loss: 0.025771444699785206, Generator Loss: 3.2192511558532715\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 24/100, Batch: 2/6, Discriminator Loss: 0.0799730084836483, Generator Loss: 2.5548346042633057\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 24/100, Batch: 3/6, Discriminator Loss: 0.05065481073449973, Generator Loss: 2.5462753772735596\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 24/100, Batch: 4/6, Discriminator Loss: 0.047413210559696495, Generator Loss: 2.677379608154297\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 24/100, Batch: 5/6, Discriminator Loss: 0.04719285395640327, Generator Loss: 2.890866279602051\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 25/100, Batch: 0/6, Discriminator Loss: 0.032555677018163545, Generator Loss: 3.2123613357543945\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 25/100, Batch: 1/6, Discriminator Loss: 0.0561772845685482, Generator Loss: 3.1360435485839844\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 25/100, Batch: 2/6, Discriminator Loss: 0.030180555762786554, Generator Loss: 3.0771923065185547\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "Epoch: 25/100, Batch: 3/6, Discriminator Loss: 0.13351001361070303, Generator Loss: 3.262514352798462\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Epoch: 25/100, Batch: 4/6, Discriminator Loss: 0.02495531950724228, Generator Loss: 3.345628261566162\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 25/100, Batch: 5/6, Discriminator Loss: 0.07845014324993826, Generator Loss: 3.864482879638672\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 26/100, Batch: 0/6, Discriminator Loss: 0.029644409267348237, Generator Loss: 5.478713035583496\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 26/100, Batch: 1/6, Discriminator Loss: 0.3112705498933792, Generator Loss: 3.22875714302063\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch: 26/100, Batch: 2/6, Discriminator Loss: 0.03137368362513371, Generator Loss: 2.824083089828491\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 26/100, Batch: 3/6, Discriminator Loss: 0.03898263494852472, Generator Loss: 2.7332382202148438\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 26/100, Batch: 4/6, Discriminator Loss: 0.04766424540173375, Generator Loss: 2.675804615020752\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch: 26/100, Batch: 5/6, Discriminator Loss: 0.06777063293543506, Generator Loss: 2.5632901191711426\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 27/100, Batch: 0/6, Discriminator Loss: 0.2521955808812777, Generator Loss: 3.8038175106048584\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Epoch: 27/100, Batch: 1/6, Discriminator Loss: 0.08029459789395332, Generator Loss: 2.8141446113586426\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 27/100, Batch: 2/6, Discriminator Loss: 0.08096142252907157, Generator Loss: 3.476027011871338\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 27/100, Batch: 3/6, Discriminator Loss: 0.01994550012750551, Generator Loss: 4.15397834777832\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 27/100, Batch: 4/6, Discriminator Loss: 0.0454141478985548, Generator Loss: 3.6206488609313965\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 27/100, Batch: 5/6, Discriminator Loss: 0.030054986951654428, Generator Loss: 4.722143173217773\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 28/100, Batch: 0/6, Discriminator Loss: 0.009218720772897981, Generator Loss: 4.118280410766602\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 28/100, Batch: 1/6, Discriminator Loss: 0.015783875191118568, Generator Loss: 3.627500057220459\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Epoch: 28/100, Batch: 2/6, Discriminator Loss: 0.03561696223914623, Generator Loss: 3.2940268516540527\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 28/100, Batch: 3/6, Discriminator Loss: 0.022511046090244236, Generator Loss: 3.2241392135620117\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Epoch: 28/100, Batch: 4/6, Discriminator Loss: 0.028744050804121457, Generator Loss: 3.0360798835754395\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "Epoch: 28/100, Batch: 5/6, Discriminator Loss: 0.1504208816911614, Generator Loss: 4.443117618560791\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 29/100, Batch: 0/6, Discriminator Loss: 0.010214478652870618, Generator Loss: 4.452328681945801\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 29/100, Batch: 1/6, Discriminator Loss: 0.21580227836966515, Generator Loss: 3.211787223815918\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 29/100, Batch: 2/6, Discriminator Loss: 0.02419145484964247, Generator Loss: 3.2216897010803223\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 29/100, Batch: 3/6, Discriminator Loss: 0.02392272270429885, Generator Loss: 3.2835216522216797\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 29/100, Batch: 4/6, Discriminator Loss: 0.07063542169635184, Generator Loss: 3.599454402923584\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "Epoch: 29/100, Batch: 5/6, Discriminator Loss: 0.07940247491933405, Generator Loss: 7.177975654602051\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 30/100, Batch: 0/6, Discriminator Loss: 0.003437110921368003, Generator Loss: 5.700562477111816\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 30/100, Batch: 1/6, Discriminator Loss: 0.4388785846531391, Generator Loss: 3.0032825469970703\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Epoch: 30/100, Batch: 2/6, Discriminator Loss: 0.03798886929143919, Generator Loss: 2.9667274951934814\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 30/100, Batch: 3/6, Discriminator Loss: 0.03107302609987528, Generator Loss: 3.2342684268951416\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 30/100, Batch: 4/6, Discriminator Loss: 0.03387945402482728, Generator Loss: 3.493959426879883\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 30/100, Batch: 5/6, Discriminator Loss: 0.02854348178516375, Generator Loss: 4.312894344329834\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 31/100, Batch: 0/6, Discriminator Loss: 0.007756758500455874, Generator Loss: 4.965595245361328\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 31/100, Batch: 1/6, Discriminator Loss: 0.2223195657134056, Generator Loss: 3.756009101867676\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "Epoch: 31/100, Batch: 2/6, Discriminator Loss: 0.08012915402650833, Generator Loss: 3.263221263885498\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 31/100, Batch: 3/6, Discriminator Loss: 0.10734533587674377, Generator Loss: 3.302260637283325\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 31/100, Batch: 4/6, Discriminator Loss: 0.03334718034602702, Generator Loss: 5.87239933013916\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "Epoch: 31/100, Batch: 5/6, Discriminator Loss: 0.007327199098654091, Generator Loss: 4.503769397735596\n",
            "1/1 [==============================] - 0s 152ms/step\n",
            "Epoch: 32/100, Batch: 0/6, Discriminator Loss: 0.010666158413181748, Generator Loss: 3.9440250396728516\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Epoch: 32/100, Batch: 1/6, Discriminator Loss: 0.043460302986204624, Generator Loss: 3.445526599884033\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch: 32/100, Batch: 2/6, Discriminator Loss: 0.06661681272089481, Generator Loss: 3.0899500846862793\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 32/100, Batch: 3/6, Discriminator Loss: 0.089864478655727, Generator Loss: 4.094520092010498\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 32/100, Batch: 4/6, Discriminator Loss: 0.006086153443902731, Generator Loss: 4.866355895996094\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 32/100, Batch: 5/6, Discriminator Loss: 0.005262743419734761, Generator Loss: 4.862007141113281\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 33/100, Batch: 0/6, Discriminator Loss: 0.005043199354979322, Generator Loss: 4.721426010131836\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 33/100, Batch: 1/6, Discriminator Loss: 0.20566926710307598, Generator Loss: 3.831409215927124\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 33/100, Batch: 2/6, Discriminator Loss: 0.01115027262858348, Generator Loss: 3.8201565742492676\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 33/100, Batch: 3/6, Discriminator Loss: 0.011072722575590888, Generator Loss: 3.8355016708374023\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 33/100, Batch: 4/6, Discriminator Loss: 0.010850862607185263, Generator Loss: 3.8574166297912598\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "Epoch: 33/100, Batch: 5/6, Discriminator Loss: 0.010618613512633601, Generator Loss: 3.88071346282959\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 34/100, Batch: 0/6, Discriminator Loss: 0.010344176759994994, Generator Loss: 3.9040462970733643\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 34/100, Batch: 1/6, Discriminator Loss: 0.010453827737364918, Generator Loss: 3.9264156818389893\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 34/100, Batch: 2/6, Discriminator Loss: 0.009893675801322388, Generator Loss: 3.9491422176361084\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 34/100, Batch: 3/6, Discriminator Loss: 0.0096674345950305, Generator Loss: 3.9718194007873535\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 34/100, Batch: 4/6, Discriminator Loss: 0.009447877896491264, Generator Loss: 3.994269609451294\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 34/100, Batch: 5/6, Discriminator Loss: 0.009251010635125567, Generator Loss: 4.016460418701172\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 35/100, Batch: 0/6, Discriminator Loss: 0.00902295857430424, Generator Loss: 4.038453102111816\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "Epoch: 35/100, Batch: 1/6, Discriminator Loss: 0.00910267501603812, Generator Loss: 4.059523582458496\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Epoch: 35/100, Batch: 2/6, Discriminator Loss: 0.008655222466586565, Generator Loss: 4.080804347991943\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Epoch: 35/100, Batch: 3/6, Discriminator Loss: 0.00846955943870853, Generator Loss: 4.102185249328613\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 35/100, Batch: 4/6, Discriminator Loss: 0.008288794264444732, Generator Loss: 4.123298168182373\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Epoch: 35/100, Batch: 5/6, Discriminator Loss: 0.008126846441882662, Generator Loss: 4.144190788269043\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 36/100, Batch: 0/6, Discriminator Loss: 0.007935878602414626, Generator Loss: 4.164892196655273\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 36/100, Batch: 1/6, Discriminator Loss: 0.008004242234164849, Generator Loss: 4.184777736663818\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 36/100, Batch: 2/6, Discriminator Loss: 0.007632596256371471, Generator Loss: 4.2049455642700195\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 36/100, Batch: 3/6, Discriminator Loss: 0.007478626304873615, Generator Loss: 4.225040912628174\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 36/100, Batch: 4/6, Discriminator Loss: 0.007328025041715591, Generator Loss: 4.244953155517578\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Epoch: 36/100, Batch: 5/6, Discriminator Loss: 0.007192791046691127, Generator Loss: 4.264717102050781\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 37/100, Batch: 0/6, Discriminator Loss: 0.007030709172955341, Generator Loss: 4.284341812133789\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 37/100, Batch: 1/6, Discriminator Loss: 0.007093774416716769, Generator Loss: 4.303194999694824\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 37/100, Batch: 2/6, Discriminator Loss: 0.006777797998438473, Generator Loss: 4.3223090171813965\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 37/100, Batch: 3/6, Discriminator Loss: 0.00664883311947051, Generator Loss: 4.3413166999816895\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 37/100, Batch: 4/6, Discriminator Loss: 0.006522370936181687, Generator Loss: 4.360220432281494\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 37/100, Batch: 5/6, Discriminator Loss: 0.006407868180758669, Generator Loss: 4.378942489624023\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 38/100, Batch: 0/6, Discriminator Loss: 0.006269551995973899, Generator Loss: 4.397532939910889\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 38/100, Batch: 1/6, Discriminator Loss: 0.0063302554917754605, Generator Loss: 4.415402412414551\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 38/100, Batch: 2/6, Discriminator Loss: 0.0060569371744350065, Generator Loss: 4.433506965637207\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 38/100, Batch: 3/6, Discriminator Loss: 0.005947899376224086, Generator Loss: 4.45154333114624\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "Epoch: 38/100, Batch: 4/6, Discriminator Loss: 0.005840324763084936, Generator Loss: 4.46958065032959\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Epoch: 38/100, Batch: 5/6, Discriminator Loss: 0.005742916680901544, Generator Loss: 4.487422466278076\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 39/100, Batch: 0/6, Discriminator Loss: 0.005623317222397617, Generator Loss: 4.505101203918457\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 39/100, Batch: 1/6, Discriminator Loss: 0.005682127666659653, Generator Loss: 4.522159576416016\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 39/100, Batch: 2/6, Discriminator Loss: 0.005443005880806595, Generator Loss: 4.5394368171691895\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 39/100, Batch: 3/6, Discriminator Loss: 0.005350305731553817, Generator Loss: 4.5565361976623535\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 39/100, Batch: 4/6, Discriminator Loss: 0.005258151501948305, Generator Loss: 4.573519706726074\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 39/100, Batch: 5/6, Discriminator Loss: 0.0051732876690948615, Generator Loss: 4.5908074378967285\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Epoch: 40/100, Batch: 0/6, Discriminator Loss: 0.005069325756035248, Generator Loss: 4.607696056365967\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 40/100, Batch: 1/6, Discriminator Loss: 0.005127825730596669, Generator Loss: 4.623894691467285\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "Epoch: 40/100, Batch: 2/6, Discriminator Loss: 0.004916178224448231, Generator Loss: 4.640404224395752\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 40/100, Batch: 3/6, Discriminator Loss: 0.004836210056964774, Generator Loss: 4.656692028045654\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 40/100, Batch: 4/6, Discriminator Loss: 0.004756553516926942, Generator Loss: 4.673030376434326\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 40/100, Batch: 5/6, Discriminator Loss: 0.004683566558014718, Generator Loss: 4.689420700073242\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 41/100, Batch: 0/6, Discriminator Loss: 0.004592181867089096, Generator Loss: 4.705385208129883\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Epoch: 41/100, Batch: 1/6, Discriminator Loss: 0.004649456881452352, Generator Loss: 4.72104024887085\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 41/100, Batch: 2/6, Discriminator Loss: 0.004460006890440127, Generator Loss: 4.736830711364746\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 41/100, Batch: 3/6, Discriminator Loss: 0.004393501485537854, Generator Loss: 4.752585411071777\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 41/100, Batch: 4/6, Discriminator Loss: 0.004323634091633721, Generator Loss: 4.76826286315918\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Epoch: 41/100, Batch: 5/6, Discriminator Loss: 0.004258779320480244, Generator Loss: 4.783818244934082\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 42/100, Batch: 0/6, Discriminator Loss: 0.004178849373321469, Generator Loss: 4.798940181732178\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Epoch: 42/100, Batch: 1/6, Discriminator Loss: 0.0042348272108938545, Generator Loss: 4.8140058517456055\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "Epoch: 42/100, Batch: 2/6, Discriminator Loss: 0.00406430075145181, Generator Loss: 4.828716278076172\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 42/100, Batch: 3/6, Discriminator Loss: 0.004005199130915571, Generator Loss: 4.8439154624938965\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 42/100, Batch: 4/6, Discriminator Loss: 0.003944603789022949, Generator Loss: 4.859122276306152\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 42/100, Batch: 5/6, Discriminator Loss: 0.003887584827680257, Generator Loss: 4.873623371124268\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 43/100, Batch: 0/6, Discriminator Loss: 0.003817074400696896, Generator Loss: 4.888693809509277\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Epoch: 43/100, Batch: 1/6, Discriminator Loss: 0.003874355366860982, Generator Loss: 4.9029741287231445\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "Epoch: 43/100, Batch: 2/6, Discriminator Loss: 0.0037187861971688108, Generator Loss: 4.916829586029053\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 43/100, Batch: 3/6, Discriminator Loss: 0.003670332851470448, Generator Loss: 4.931098937988281\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 43/100, Batch: 4/6, Discriminator Loss: 0.0036129484351477004, Generator Loss: 4.946249961853027\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 43/100, Batch: 5/6, Discriminator Loss: 0.0035641994218167383, Generator Loss: 4.959181785583496\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 44/100, Batch: 0/6, Discriminator Loss: 0.0035059102723646873, Generator Loss: 4.973356246948242\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 44/100, Batch: 1/6, Discriminator Loss: 0.0035646682808874175, Generator Loss: 4.987119197845459\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 44/100, Batch: 2/6, Discriminator Loss: 0.0034213909675600007, Generator Loss: 4.999964237213135\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 44/100, Batch: 3/6, Discriminator Loss: 0.003378561024874216, Generator Loss: 5.013535499572754\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Epoch: 44/100, Batch: 4/6, Discriminator Loss: 0.0033466311415395467, Generator Loss: 5.024273872375488\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 44/100, Batch: 5/6, Discriminator Loss: 0.0033022241696016863, Generator Loss: 5.037179946899414\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 45/100, Batch: 0/6, Discriminator Loss: 0.0032573102927511144, Generator Loss: 5.040005207061768\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 45/100, Batch: 1/6, Discriminator Loss: 0.003394101615413092, Generator Loss: 5.046463966369629\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 45/100, Batch: 2/6, Discriminator Loss: 0.0034489082390791737, Generator Loss: 5.011828899383545\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch: 45/100, Batch: 3/6, Discriminator Loss: 0.004305623508116696, Generator Loss: 4.864302635192871\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 45/100, Batch: 4/6, Discriminator Loss: 0.010835156099346932, Generator Loss: 4.785928726196289\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 45/100, Batch: 5/6, Discriminator Loss: 0.0196465996614279, Generator Loss: 4.890834808349609\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 46/100, Batch: 0/6, Discriminator Loss: 0.003346591646376851, Generator Loss: 6.404953479766846\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 46/100, Batch: 1/6, Discriminator Loss: 0.12046733847819269, Generator Loss: 4.80726957321167\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Epoch: 46/100, Batch: 2/6, Discriminator Loss: 0.015209257860078651, Generator Loss: 5.029019832611084\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "Epoch: 46/100, Batch: 3/6, Discriminator Loss: 0.004397467573653557, Generator Loss: 5.77893590927124\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Epoch: 46/100, Batch: 4/6, Discriminator Loss: 0.002798635550789186, Generator Loss: 5.529619216918945\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 46/100, Batch: 5/6, Discriminator Loss: 0.002578268529759953, Generator Loss: 5.293321132659912\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 47/100, Batch: 0/6, Discriminator Loss: 0.0026707214914090116, Generator Loss: 5.243408203125\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 47/100, Batch: 1/6, Discriminator Loss: 0.08860461367294192, Generator Loss: 5.201932907104492\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 47/100, Batch: 2/6, Discriminator Loss: 0.002784124248137232, Generator Loss: 5.201111316680908\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 47/100, Batch: 3/6, Discriminator Loss: 0.002780497108687996, Generator Loss: 5.210464954376221\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 47/100, Batch: 4/6, Discriminator Loss: 0.0027394867338443873, Generator Loss: 5.222403526306152\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "Epoch: 47/100, Batch: 5/6, Discriminator Loss: 0.002721964674492483, Generator Loss: 5.234889030456543\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Epoch: 48/100, Batch: 0/6, Discriminator Loss: 0.0026596741783428968, Generator Loss: 5.247476577758789\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "Epoch: 48/100, Batch: 1/6, Discriminator Loss: 0.08471713378094137, Generator Loss: 5.204832077026367\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 48/100, Batch: 2/6, Discriminator Loss: 0.0027748528045776766, Generator Loss: 5.203854084014893\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 48/100, Batch: 3/6, Discriminator Loss: 0.0027697453697328456, Generator Loss: 5.213253498077393\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 48/100, Batch: 4/6, Discriminator Loss: 0.0027302958769723773, Generator Loss: 5.2252702713012695\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 48/100, Batch: 5/6, Discriminator Loss: 0.002709133503230987, Generator Loss: 5.237880229949951\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 49/100, Batch: 0/6, Discriminator Loss: 0.0026515449391837365, Generator Loss: 5.250629901885986\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 49/100, Batch: 1/6, Discriminator Loss: 0.08475904306396842, Generator Loss: 5.207372665405273\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "Epoch: 49/100, Batch: 2/6, Discriminator Loss: 0.002766946100109635, Generator Loss: 5.206351280212402\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "Epoch: 49/100, Batch: 3/6, Discriminator Loss: 0.0027606405528786127, Generator Loss: 5.215856075286865\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 49/100, Batch: 4/6, Discriminator Loss: 0.002722014552091423, Generator Loss: 5.228009223937988\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 49/100, Batch: 5/6, Discriminator Loss: 0.002698114447412081, Generator Loss: 5.240762233734131\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 50/100, Batch: 0/6, Discriminator Loss: 0.0026437694877863294, Generator Loss: 5.253647804260254\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 50/100, Batch: 1/6, Discriminator Loss: 0.08479945734143257, Generator Loss: 5.209662437438965\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 50/100, Batch: 2/6, Discriminator Loss: 0.0027600637658906635, Generator Loss: 5.208590984344482\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 50/100, Batch: 3/6, Discriminator Loss: 0.002752757531197858, Generator Loss: 5.218218803405762\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 50/100, Batch: 4/6, Discriminator Loss: 0.002714629015827086, Generator Loss: 5.230530738830566\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 50/100, Batch: 5/6, Discriminator Loss: 0.0026885737188422354, Generator Loss: 5.2434539794921875\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "Epoch: 51/100, Batch: 0/6, Discriminator Loss: 0.002636496327660609, Generator Loss: 5.256497383117676\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "Epoch: 51/100, Batch: 1/6, Discriminator Loss: 0.08483750466257334, Generator Loss: 5.211888313293457\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 51/100, Batch: 2/6, Discriminator Loss: 0.0027534993678273167, Generator Loss: 5.210772514343262\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 51/100, Batch: 3/6, Discriminator Loss: 0.002745406211943191, Generator Loss: 5.2205047607421875\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 51/100, Batch: 4/6, Discriminator Loss: 0.002707668581024336, Generator Loss: 5.232953071594238\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 51/100, Batch: 5/6, Discriminator Loss: 0.002679894332686672, Generator Loss: 5.246020317077637\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 52/100, Batch: 0/6, Discriminator Loss: 0.0026295959925803913, Generator Loss: 5.259211540222168\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Epoch: 52/100, Batch: 1/6, Discriminator Loss: 0.08487379481084645, Generator Loss: 5.213998794555664\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 52/100, Batch: 2/6, Discriminator Loss: 0.002747385653492529, Generator Loss: 5.2128448486328125\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 52/100, Batch: 3/6, Discriminator Loss: 0.0027385856719774893, Generator Loss: 5.222682952880859\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Epoch: 52/100, Batch: 4/6, Discriminator Loss: 0.0027011145548385684, Generator Loss: 5.235269069671631\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Epoch: 52/100, Batch: 5/6, Discriminator Loss: 0.002671927730261814, Generator Loss: 5.248482704162598\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 53/100, Batch: 0/6, Discriminator Loss: 0.0026229839649616338, Generator Loss: 5.26181697845459\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 53/100, Batch: 1/6, Discriminator Loss: 0.08490871079266071, Generator Loss: 5.2159810066223145\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 53/100, Batch: 2/6, Discriminator Loss: 0.0027417298392720113, Generator Loss: 5.214783668518066\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 53/100, Batch: 3/6, Discriminator Loss: 0.002732303961238358, Generator Loss: 5.22472620010376\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 53/100, Batch: 4/6, Discriminator Loss: 0.0026950174069497734, Generator Loss: 5.2374491691589355\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 53/100, Batch: 5/6, Discriminator Loss: 0.002664632526830246, Generator Loss: 5.25080680847168\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 54/100, Batch: 0/6, Discriminator Loss: 0.002616751490304381, Generator Loss: 5.264282703399658\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 54/100, Batch: 1/6, Discriminator Loss: 0.08494183351285756, Generator Loss: 5.217827320098877\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 54/100, Batch: 2/6, Discriminator Loss: 0.002736516781624232, Generator Loss: 5.216588497161865\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 54/100, Batch: 3/6, Discriminator Loss: 0.0027265225780865876, Generator Loss: 5.226634979248047\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 54/100, Batch: 4/6, Discriminator Loss: 0.002689347785690188, Generator Loss: 5.239496231079102\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 54/100, Batch: 5/6, Discriminator Loss: 0.0026579279992802185, Generator Loss: 5.252999782562256\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 55/100, Batch: 0/6, Discriminator Loss: 0.002610879936479904, Generator Loss: 5.266605854034424\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 55/100, Batch: 1/6, Discriminator Loss: 0.08497300278395414, Generator Loss: 5.219586372375488\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 55/100, Batch: 2/6, Discriminator Loss: 0.002731586106165196, Generator Loss: 5.218303203582764\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 55/100, Batch: 3/6, Discriminator Loss: 0.0027211202577746008, Generator Loss: 5.228436470031738\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 55/100, Batch: 4/6, Discriminator Loss: 0.0026840495602300507, Generator Loss: 5.241413593292236\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "Epoch: 55/100, Batch: 5/6, Discriminator Loss: 0.0026517844780755695, Generator Loss: 5.255040168762207\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Epoch: 56/100, Batch: 0/6, Discriminator Loss: 0.0026054368232983904, Generator Loss: 5.268769264221191\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "Epoch: 56/100, Batch: 1/6, Discriminator Loss: 0.08500136574730277, Generator Loss: 5.221559047698975\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 56/100, Batch: 2/6, Discriminator Loss: 0.002726001278460899, Generator Loss: 5.220245838165283\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 56/100, Batch: 3/6, Discriminator Loss: 0.002715233262279071, Generator Loss: 5.230391502380371\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 56/100, Batch: 4/6, Discriminator Loss: 0.0026784686942846747, Generator Loss: 5.24338960647583\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 56/100, Batch: 5/6, Discriminator Loss: 0.002645714699610835, Generator Loss: 5.257040023803711\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 57/100, Batch: 0/6, Discriminator Loss: 0.002600198623088801, Generator Loss: 5.2707953453063965\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 57/100, Batch: 1/6, Discriminator Loss: 0.08502879436127841, Generator Loss: 5.222980499267578\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 57/100, Batch: 2/6, Discriminator Loss: 0.002722089368489833, Generator Loss: 5.221627712249756\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 57/100, Batch: 3/6, Discriminator Loss: 0.0027108676458738046, Generator Loss: 5.231876373291016\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Epoch: 57/100, Batch: 4/6, Discriminator Loss: 0.0026740884886748972, Generator Loss: 5.245009899139404\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 57/100, Batch: 5/6, Discriminator Loss: 0.0026405934058857383, Generator Loss: 5.258800983428955\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 58/100, Batch: 0/6, Discriminator Loss: 0.0025954868679924914, Generator Loss: 5.272702217102051\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 58/100, Batch: 1/6, Discriminator Loss: 0.08505464717745781, Generator Loss: 5.22430944442749\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 58/100, Batch: 2/6, Discriminator Loss: 0.002718451442433434, Generator Loss: 5.22292423248291\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 58/100, Batch: 3/6, Discriminator Loss: 0.002706811874304549, Generator Loss: 5.233276844024658\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 58/100, Batch: 4/6, Discriminator Loss: 0.0026699709951572004, Generator Loss: 5.246546745300293\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 58/100, Batch: 5/6, Discriminator Loss: 0.002635789704072522, Generator Loss: 5.260479927062988\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 59/100, Batch: 0/6, Discriminator Loss: 0.002590996794477718, Generator Loss: 5.2745208740234375\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 59/100, Batch: 1/6, Discriminator Loss: 0.08507950999774039, Generator Loss: 5.225475311279297\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 59/100, Batch: 2/6, Discriminator Loss: 0.002715311982683488, Generator Loss: 5.224051475524902\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 59/100, Batch: 3/6, Discriminator Loss: 0.002703262055547384, Generator Loss: 5.234519004821777\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch: 59/100, Batch: 4/6, Discriminator Loss: 0.002666291923105746, Generator Loss: 5.2479400634765625\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 59/100, Batch: 5/6, Discriminator Loss: 0.0026314246006222675, Generator Loss: 5.262031555175781\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 60/100, Batch: 0/6, Discriminator Loss: 0.002586833867724181, Generator Loss: 5.276228904724121\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 60/100, Batch: 1/6, Discriminator Loss: 0.08510279562324286, Generator Loss: 5.226606369018555\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 60/100, Batch: 2/6, Discriminator Loss: 0.002712257949042396, Generator Loss: 5.225152015686035\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 60/100, Batch: 3/6, Discriminator Loss: 0.002699824261071626, Generator Loss: 5.2357258796691895\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 60/100, Batch: 4/6, Discriminator Loss: 0.002662738392700703, Generator Loss: 5.249284744262695\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Epoch: 60/100, Batch: 5/6, Discriminator Loss: 0.0026272589507243538, Generator Loss: 5.263520240783691\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 61/100, Batch: 0/6, Discriminator Loss: 0.002582850465174147, Generator Loss: 5.277860164642334\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 61/100, Batch: 1/6, Discriminator Loss: 0.085124964825809, Generator Loss: 5.227721214294434\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 61/100, Batch: 2/6, Discriminator Loss: 0.0027092496648037923, Generator Loss: 5.226233959197998\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 61/100, Batch: 3/6, Discriminator Loss: 0.0026964779317495413, Generator Loss: 5.236896514892578\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 61/100, Batch: 4/6, Discriminator Loss: 0.0026593204324854014, Generator Loss: 5.250571250915527\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 61/100, Batch: 5/6, Discriminator Loss: 0.0026233212179249676, Generator Loss: 5.264928817749023\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 62/100, Batch: 0/6, Discriminator Loss: 0.0025791012976341676, Generator Loss: 5.279389381408691\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 62/100, Batch: 1/6, Discriminator Loss: 0.08514595334418118, Generator Loss: 5.228668212890625\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 62/100, Batch: 2/6, Discriminator Loss: 0.00270673821296441, Generator Loss: 5.227148056030273\n",
            "1/1 [==============================] - 0s 164ms/step\n",
            "Epoch: 62/100, Batch: 3/6, Discriminator Loss: 0.0026936092108371668, Generator Loss: 5.237916469573975\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Epoch: 62/100, Batch: 4/6, Discriminator Loss: 0.002656304797710618, Generator Loss: 5.251730442047119\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 62/100, Batch: 5/6, Discriminator Loss: 0.0026197535112260084, Generator Loss: 5.266232967376709\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 63/100, Batch: 0/6, Discriminator Loss: 0.0025756061681434517, Generator Loss: 5.280836582183838\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 63/100, Batch: 1/6, Discriminator Loss: 0.08516588225029409, Generator Loss: 5.229532241821289\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 63/100, Batch: 2/6, Discriminator Loss: 0.002704462865494861, Generator Loss: 5.2279815673828125\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "Epoch: 63/100, Batch: 3/6, Discriminator Loss: 0.0026909886873909272, Generator Loss: 5.238855361938477\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "Epoch: 63/100, Batch: 4/6, Discriminator Loss: 0.002653517897670099, Generator Loss: 5.252808094024658\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "Epoch: 63/100, Batch: 5/6, Discriminator Loss: 0.0026164411915488017, Generator Loss: 5.267455101013184\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 64/100, Batch: 0/6, Discriminator Loss: 0.0025723275813049895, Generator Loss: 5.282202243804932\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 64/100, Batch: 1/6, Discriminator Loss: 0.08518475317396224, Generator Loss: 5.23031759262085\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Epoch: 64/100, Batch: 2/6, Discriminator Loss: 0.002702413115002855, Generator Loss: 5.228735446929932\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 64/100, Batch: 3/6, Discriminator Loss: 0.0026886018417826563, Generator Loss: 5.239716529846191\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 64/100, Batch: 4/6, Discriminator Loss: 0.002650949493272492, Generator Loss: 5.253808498382568\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 64/100, Batch: 5/6, Discriminator Loss: 0.0026133650817428133, Generator Loss: 5.268600940704346\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 65/100, Batch: 0/6, Discriminator Loss: 0.002569248543172975, Generator Loss: 5.283490180969238\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 65/100, Batch: 1/6, Discriminator Loss: 0.08520265086553991, Generator Loss: 5.231007099151611\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Epoch: 65/100, Batch: 2/6, Discriminator Loss: 0.002700643205344022, Generator Loss: 5.229390621185303\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 65/100, Batch: 3/6, Discriminator Loss: 0.0026865095751418266, Generator Loss: 5.240479469299316\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 65/100, Batch: 4/6, Discriminator Loss: 0.0026486576307434007, Generator Loss: 5.254712104797363\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Epoch: 65/100, Batch: 5/6, Discriminator Loss: 0.002610576113056595, Generator Loss: 5.269651889801025\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 66/100, Batch: 0/6, Discriminator Loss: 0.002566418417050187, Generator Loss: 5.284686088562012\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 66/100, Batch: 1/6, Discriminator Loss: 0.08521919418126345, Generator Loss: 5.231688022613525\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 66/100, Batch: 2/6, Discriminator Loss: 0.0026988733211510407, Generator Loss: 5.230046272277832\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 66/100, Batch: 3/6, Discriminator Loss: 0.002684430868612253, Generator Loss: 5.241231441497803\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 66/100, Batch: 4/6, Discriminator Loss: 0.002646413450293039, Generator Loss: 5.255588054656982\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "Epoch: 66/100, Batch: 5/6, Discriminator Loss: 0.0026078981600221596, Generator Loss: 5.270658493041992\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Epoch: 67/100, Batch: 0/6, Discriminator Loss: 0.002563716811611272, Generator Loss: 5.285822868347168\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Epoch: 67/100, Batch: 1/6, Discriminator Loss: 0.0852351551875472, Generator Loss: 5.232221603393555\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 67/100, Batch: 2/6, Discriminator Loss: 0.0026975453934028337, Generator Loss: 5.23054838180542\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 67/100, Batch: 3/6, Discriminator Loss: 0.0026827808242160245, Generator Loss: 5.24184513092041\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 67/100, Batch: 4/6, Discriminator Loss: 0.002644533454258635, Generator Loss: 5.256346225738525\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 67/100, Batch: 5/6, Discriminator Loss: 0.002605541991215432, Generator Loss: 5.271566867828369\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 68/100, Batch: 0/6, Discriminator Loss: 0.0025612520051616627, Generator Loss: 5.286882400512695\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "Epoch: 68/100, Batch: 1/6, Discriminator Loss: 0.08524999464862049, Generator Loss: 5.232734203338623\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 68/100, Batch: 2/6, Discriminator Loss: 0.002696257219895415, Generator Loss: 5.231039047241211\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 68/100, Batch: 3/6, Discriminator Loss: 0.0026811726902451483, Generator Loss: 5.24244499206543\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 68/100, Batch: 4/6, Discriminator Loss: 0.0026426970262036775, Generator Loss: 5.257087230682373\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 68/100, Batch: 5/6, Discriminator Loss: 0.0026032495879917406, Generator Loss: 5.272454261779785\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 69/100, Batch: 0/6, Discriminator Loss: 0.0025588486820513623, Generator Loss: 5.287914276123047\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 69/100, Batch: 1/6, Discriminator Loss: 0.08526452910155058, Generator Loss: 5.233194351196289\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 69/100, Batch: 2/6, Discriminator Loss: 0.002695128075629327, Generator Loss: 5.231471538543701\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 69/100, Batch: 3/6, Discriminator Loss: 0.0026797449818332097, Generator Loss: 5.242985248565674\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 69/100, Batch: 4/6, Discriminator Loss: 0.0026410344994474144, Generator Loss: 5.257767200469971\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Epoch: 69/100, Batch: 5/6, Discriminator Loss: 0.002601141757622827, Generator Loss: 5.273279666900635\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 70/100, Batch: 0/6, Discriminator Loss: 0.002556607418835455, Generator Loss: 5.288885116577148\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Epoch: 70/100, Batch: 1/6, Discriminator Loss: 0.08527826727367938, Generator Loss: 5.233597755432129\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "Epoch: 70/100, Batch: 2/6, Discriminator Loss: 0.0026941558585349412, Generator Loss: 5.23184871673584\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "Epoch: 70/100, Batch: 3/6, Discriminator Loss: 0.002678467653822736, Generator Loss: 5.243472576141357\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 70/100, Batch: 4/6, Discriminator Loss: 0.0026395146030608885, Generator Loss: 5.258395671844482\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 70/100, Batch: 5/6, Discriminator Loss: 0.0025991778570642055, Generator Loss: 5.274056434631348\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 71/100, Batch: 0/6, Discriminator Loss: 0.002554489790794534, Generator Loss: 5.289806365966797\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 71/100, Batch: 1/6, Discriminator Loss: 0.08529173070564866, Generator Loss: 5.233765125274658\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 71/100, Batch: 2/6, Discriminator Loss: 0.0026938822065858403, Generator Loss: 5.231980323791504\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 71/100, Batch: 3/6, Discriminator Loss: 0.0026778374403875205, Generator Loss: 5.243746280670166\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "Epoch: 71/100, Batch: 4/6, Discriminator Loss: 0.0026385243611457554, Generator Loss: 5.258855819702148\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "Epoch: 71/100, Batch: 5/6, Discriminator Loss: 0.002597632507331582, Generator Loss: 5.2747087478637695\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Epoch: 72/100, Batch: 0/6, Discriminator Loss: 0.0025526548112910774, Generator Loss: 5.290651321411133\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 72/100, Batch: 1/6, Discriminator Loss: 0.08530376758426428, Generator Loss: 5.234081268310547\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Epoch: 72/100, Batch: 2/6, Discriminator Loss: 0.0026931327631700697, Generator Loss: 5.232281684875488\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 72/100, Batch: 3/6, Discriminator Loss: 0.0026767860795189335, Generator Loss: 5.2441606521606445\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 72/100, Batch: 4/6, Discriminator Loss: 0.002637208478518005, Generator Loss: 5.25941276550293\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch: 72/100, Batch: 5/6, Discriminator Loss: 0.0025958879184599937, Generator Loss: 5.2754130363464355\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 73/100, Batch: 0/6, Discriminator Loss: 0.0025507246276355033, Generator Loss: 5.291502952575684\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 73/100, Batch: 1/6, Discriminator Loss: 0.08531594835221767, Generator Loss: 5.234366416931152\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 73/100, Batch: 2/6, Discriminator Loss: 0.002692488123784642, Generator Loss: 5.232542514801025\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Epoch: 73/100, Batch: 3/6, Discriminator Loss: 0.0026758547237477615, Generator Loss: 5.244532585144043\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 73/100, Batch: 4/6, Discriminator Loss: 0.002636010939568223, Generator Loss: 5.259927272796631\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 73/100, Batch: 5/6, Discriminator Loss: 0.002594268067696248, Generator Loss: 5.276075839996338\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 74/100, Batch: 0/6, Discriminator Loss: 0.002548905511801536, Generator Loss: 5.292312145233154\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 74/100, Batch: 1/6, Discriminator Loss: 0.08532759454101324, Generator Loss: 5.234610557556152\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 74/100, Batch: 2/6, Discriminator Loss: 0.002691958096193048, Generator Loss: 5.232762336730957\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 74/100, Batch: 3/6, Discriminator Loss: 0.0026750450319923402, Generator Loss: 5.244863986968994\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 74/100, Batch: 4/6, Discriminator Loss: 0.0026349250515522726, Generator Loss: 5.260401248931885\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 74/100, Batch: 5/6, Discriminator Loss: 0.0025927610743110563, Generator Loss: 5.276699066162109\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "Epoch: 75/100, Batch: 0/6, Discriminator Loss: 0.0025471865239872216, Generator Loss: 5.293082237243652\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Epoch: 75/100, Batch: 1/6, Discriminator Loss: 0.08533872244879603, Generator Loss: 5.234817028045654\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 75/100, Batch: 2/6, Discriminator Loss: 0.0026915315850146726, Generator Loss: 5.232945442199707\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 75/100, Batch: 3/6, Discriminator Loss: 0.002674343380931532, Generator Loss: 5.245158672332764\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 75/100, Batch: 4/6, Discriminator Loss: 0.002633940441228333, Generator Loss: 5.260838508605957\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 75/100, Batch: 5/6, Discriminator Loss: 0.002591362571820355, Generator Loss: 5.277284145355225\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 76/100, Batch: 0/6, Discriminator Loss: 0.0025455622980850023, Generator Loss: 5.2938151359558105\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 76/100, Batch: 1/6, Discriminator Loss: 0.08534936583600938, Generator Loss: 5.234987735748291\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 76/100, Batch: 2/6, Discriminator Loss: 0.0026912028406513855, Generator Loss: 5.23309326171875\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Epoch: 76/100, Batch: 3/6, Discriminator Loss: 0.0026737415546449483, Generator Loss: 5.245417594909668\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "Epoch: 76/100, Batch: 4/6, Discriminator Loss: 0.0026330524108288955, Generator Loss: 5.2612409591674805\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 76/100, Batch: 5/6, Discriminator Loss: 0.0025900592424932256, Generator Loss: 5.277836799621582\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 77/100, Batch: 0/6, Discriminator Loss: 0.002544027250618086, Generator Loss: 5.294515132904053\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 77/100, Batch: 1/6, Discriminator Loss: 0.08535960176959634, Generator Loss: 5.235115051269531\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 77/100, Batch: 2/6, Discriminator Loss: 0.002690996834303405, Generator Loss: 5.233196258544922\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 77/100, Batch: 3/6, Discriminator Loss: 0.0026732635305961594, Generator Loss: 5.245634078979492\n",
            "1/1 [==============================] - 0s 166ms/step\n",
            "Epoch: 77/100, Batch: 4/6, Discriminator Loss: 0.002632278208011485, Generator Loss: 5.261603832244873\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "Epoch: 77/100, Batch: 5/6, Discriminator Loss: 0.0025888686145663087, Generator Loss: 5.278350353240967\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "Epoch: 78/100, Batch: 0/6, Discriminator Loss: 0.0025425897641611073, Generator Loss: 5.295177936553955\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 78/100, Batch: 1/6, Discriminator Loss: 0.0853693108074367, Generator Loss: 5.235228061676025\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 78/100, Batch: 2/6, Discriminator Loss: 0.002690820864017951, Generator Loss: 5.233290195465088\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 78/100, Batch: 3/6, Discriminator Loss: 0.0026728220655058976, Generator Loss: 5.245838642120361\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "Epoch: 78/100, Batch: 4/6, Discriminator Loss: 0.0026315449151752546, Generator Loss: 5.261950492858887\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "Epoch: 78/100, Batch: 5/6, Discriminator Loss: 0.002587728416074242, Generator Loss: 5.278844356536865\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Epoch: 79/100, Batch: 0/6, Discriminator Loss: 0.002541205600833152, Generator Loss: 5.295816421508789\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 79/100, Batch: 1/6, Discriminator Loss: 0.08537867898121476, Generator Loss: 5.235328674316406\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 79/100, Batch: 2/6, Discriminator Loss: 0.002690682330467098, Generator Loss: 5.233367443084717\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Epoch: 79/100, Batch: 3/6, Discriminator Loss: 0.0026724337717496383, Generator Loss: 5.2460222244262695\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 79/100, Batch: 4/6, Discriminator Loss: 0.002630875613021999, Generator Loss: 5.262269973754883\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 79/100, Batch: 5/6, Discriminator Loss: 0.002586674552730983, Generator Loss: 5.279304504394531\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 80/100, Batch: 0/6, Discriminator Loss: 0.002539909917775418, Generator Loss: 5.296418190002441\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 80/100, Batch: 1/6, Discriminator Loss: 0.08538757869973779, Generator Loss: 5.2353901863098145\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "Epoch: 80/100, Batch: 2/6, Discriminator Loss: 0.002690650027943775, Generator Loss: 5.233407497406006\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Epoch: 80/100, Batch: 3/6, Discriminator Loss: 0.002672148727469903, Generator Loss: 5.246170520782471\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 80/100, Batch: 4/6, Discriminator Loss: 0.00263029471216214, Generator Loss: 5.2625579833984375\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 80/100, Batch: 5/6, Discriminator Loss: 0.002585703154636576, Generator Loss: 5.279737949371338\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 81/100, Batch: 0/6, Discriminator Loss: 0.0025386878015378755, Generator Loss: 5.296994209289551\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 81/100, Batch: 1/6, Discriminator Loss: 0.08539626142010093, Generator Loss: 5.235366344451904\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 81/100, Batch: 2/6, Discriminator Loss: 0.0026908631392643656, Generator Loss: 5.233363151550293\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 81/100, Batch: 3/6, Discriminator Loss: 0.0026720838959590765, Generator Loss: 5.246248722076416\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 81/100, Batch: 4/6, Discriminator Loss: 0.002629890135494861, Generator Loss: 5.262793064117432\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "Epoch: 81/100, Batch: 5/6, Discriminator Loss: 0.0025848583120477997, Generator Loss: 5.280134201049805\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 82/100, Batch: 0/6, Discriminator Loss: 0.002537536706887167, Generator Loss: 5.297553062438965\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Epoch: 82/100, Batch: 1/6, Discriminator Loss: 0.08540483540855348, Generator Loss: 5.235270023345947\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 82/100, Batch: 2/6, Discriminator Loss: 0.0026912948536619297, Generator Loss: 5.233243465423584\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 82/100, Batch: 3/6, Discriminator Loss: 0.0026722274506028043, Generator Loss: 5.246262550354004\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 82/100, Batch: 4/6, Discriminator Loss: 0.0026296513717625203, Generator Loss: 5.262975692749023\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 82/100, Batch: 5/6, Discriminator Loss: 0.002584144168167768, Generator Loss: 5.280494689941406\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 83/100, Batch: 0/6, Discriminator Loss: 0.0025364710732311835, Generator Loss: 5.298087120056152\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 83/100, Batch: 1/6, Discriminator Loss: 0.08541286247782409, Generator Loss: 5.235263347625732\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 83/100, Batch: 2/6, Discriminator Loss: 0.0026914505735931016, Generator Loss: 5.233219623565674\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 83/100, Batch: 3/6, Discriminator Loss: 0.002672121069736022, Generator Loss: 5.246353626251221\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "Epoch: 83/100, Batch: 4/6, Discriminator Loss: 0.002629227092484143, Generator Loss: 5.263213634490967\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Epoch: 83/100, Batch: 5/6, Discriminator Loss: 0.002583314333605813, Generator Loss: 5.280882358551025\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 84/100, Batch: 0/6, Discriminator Loss: 0.0025353565439392156, Generator Loss: 5.298623561859131\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 84/100, Batch: 1/6, Discriminator Loss: 0.08542090421542525, Generator Loss: 5.235262393951416\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 84/100, Batch: 2/6, Discriminator Loss: 0.002691589239361747, Generator Loss: 5.233198165893555\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 84/100, Batch: 3/6, Discriminator Loss: 0.0026720250680227764, Generator Loss: 5.246438503265381\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 84/100, Batch: 4/6, Discriminator Loss: 0.0026288315220881486, Generator Loss: 5.2634358406066895\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 84/100, Batch: 5/6, Discriminator Loss: 0.002582538144679347, Generator Loss: 5.281247138977051\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "Epoch: 85/100, Batch: 0/6, Discriminator Loss: 0.00253431001007165, Generator Loss: 5.299129962921143\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Epoch: 85/100, Batch: 1/6, Discriminator Loss: 0.08542858925648034, Generator Loss: 5.2352190017700195\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 85/100, Batch: 2/6, Discriminator Loss: 0.002691847854180196, Generator Loss: 5.233136177062988\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 85/100, Batch: 3/6, Discriminator Loss: 0.002672027054359205, Generator Loss: 5.246492862701416\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 85/100, Batch: 4/6, Discriminator Loss: 0.0026285112469395244, Generator Loss: 5.263635635375977\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 85/100, Batch: 5/6, Discriminator Loss: 0.002581812698053909, Generator Loss: 5.2815985679626465\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Epoch: 86/100, Batch: 0/6, Discriminator Loss: 0.002533287688285313, Generator Loss: 5.299628734588623\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 86/100, Batch: 1/6, Discriminator Loss: 0.08543591224588454, Generator Loss: 5.235293865203857\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 86/100, Batch: 2/6, Discriminator Loss: 0.002691753438057276, Generator Loss: 5.2331929206848145\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Epoch: 86/100, Batch: 3/6, Discriminator Loss: 0.0026717462408214487, Generator Loss: 5.246630668640137\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Epoch: 86/100, Batch: 4/6, Discriminator Loss: 0.00262800559767129, Generator Loss: 5.26387882232666\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 86/100, Batch: 5/6, Discriminator Loss: 0.002581021234846048, Generator Loss: 5.281950950622559\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 87/100, Batch: 0/6, Discriminator Loss: 0.002532298444405612, Generator Loss: 5.300091743469238\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "Epoch: 87/100, Batch: 1/6, Discriminator Loss: 0.08544301288202405, Generator Loss: 5.235217094421387\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 87/100, Batch: 2/6, Discriminator Loss: 0.002692101095021826, Generator Loss: 5.233098983764648\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 87/100, Batch: 3/6, Discriminator Loss: 0.002671847389137838, Generator Loss: 5.246650218963623\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 87/100, Batch: 4/6, Discriminator Loss: 0.0026277828922047775, Generator Loss: 5.264041900634766\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 87/100, Batch: 5/6, Discriminator Loss: 0.0025804032823089074, Generator Loss: 5.28226375579834\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Epoch: 88/100, Batch: 0/6, Discriminator Loss: 0.002531379274580914, Generator Loss: 5.300551891326904\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Epoch: 88/100, Batch: 1/6, Discriminator Loss: 0.08545010397210717, Generator Loss: 5.235123634338379\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 88/100, Batch: 2/6, Discriminator Loss: 0.002692500888315408, Generator Loss: 5.232987403869629\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 88/100, Batch: 3/6, Discriminator Loss: 0.0026719961515482282, Generator Loss: 5.246653079986572\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 88/100, Batch: 4/6, Discriminator Loss: 0.0026276020410023193, Generator Loss: 5.2641921043396\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 88/100, Batch: 5/6, Discriminator Loss: 0.0025798224171467155, Generator Loss: 5.282564163208008\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 89/100, Batch: 0/6, Discriminator Loss: 0.0025304859505048682, Generator Loss: 5.3010029792785645\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "Epoch: 89/100, Batch: 1/6, Discriminator Loss: 0.08545707957819104, Generator Loss: 5.235018730163574\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 89/100, Batch: 2/6, Discriminator Loss: 0.002692932054628727, Generator Loss: 5.232863426208496\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Epoch: 89/100, Batch: 3/6, Discriminator Loss: 0.002672180164609017, Generator Loss: 5.246645450592041\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 89/100, Batch: 4/6, Discriminator Loss: 0.002627451612852383, Generator Loss: 5.264330863952637\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 89/100, Batch: 5/6, Discriminator Loss: 0.0025792727280986583, Generator Loss: 5.28285551071167\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 90/100, Batch: 0/6, Discriminator Loss: 0.0025296203357161318, Generator Loss: 5.301443099975586\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 90/100, Batch: 1/6, Discriminator Loss: 0.08546391176059842, Generator Loss: 5.234903335571289\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 90/100, Batch: 2/6, Discriminator Loss: 0.0026933931595749527, Generator Loss: 5.232730388641357\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 90/100, Batch: 3/6, Discriminator Loss: 0.0026723946398305998, Generator Loss: 5.246627330780029\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 90/100, Batch: 4/6, Discriminator Loss: 0.0026273294013208215, Generator Loss: 5.264459133148193\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 90/100, Batch: 5/6, Discriminator Loss: 0.0025787513598061196, Generator Loss: 5.283135890960693\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 91/100, Batch: 0/6, Discriminator Loss: 0.0025287796376005645, Generator Loss: 5.301875591278076\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Epoch: 91/100, Batch: 1/6, Discriminator Loss: 0.08547064941376448, Generator Loss: 5.23477840423584\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "Epoch: 91/100, Batch: 2/6, Discriminator Loss: 0.002693880729339071, Generator Loss: 5.232586860656738\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "Epoch: 91/100, Batch: 3/6, Discriminator Loss: 0.002672636992429034, Generator Loss: 5.246600151062012\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 91/100, Batch: 4/6, Discriminator Loss: 0.002627230912594314, Generator Loss: 5.264580249786377\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 91/100, Batch: 5/6, Discriminator Loss: 0.0025782548324286836, Generator Loss: 5.2834086418151855\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 92/100, Batch: 0/6, Discriminator Loss: 0.002527960130619178, Generator Loss: 5.302297592163086\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 92/100, Batch: 1/6, Discriminator Loss: 0.08547724690288305, Generator Loss: 5.234644412994385\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 92/100, Batch: 2/6, Discriminator Loss: 0.0026943925914793, Generator Loss: 5.23243522644043\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 92/100, Batch: 3/6, Discriminator Loss: 0.002672906185125612, Generator Loss: 5.2465643882751465\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 92/100, Batch: 4/6, Discriminator Loss: 0.002627157053211704, Generator Loss: 5.264691352844238\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "Epoch: 92/100, Batch: 5/6, Discriminator Loss: 0.002577781312879779, Generator Loss: 5.283673286437988\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 93/100, Batch: 0/6, Discriminator Loss: 0.0025271594860765134, Generator Loss: 5.302713394165039\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 93/100, Batch: 1/6, Discriminator Loss: 0.08548376988619566, Generator Loss: 5.23450231552124\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 93/100, Batch: 2/6, Discriminator Loss: 0.0026949288104560765, Generator Loss: 5.23227596282959\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 93/100, Batch: 3/6, Discriminator Loss: 0.002673197674084804, Generator Loss: 5.24652099609375\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Epoch: 93/100, Batch: 4/6, Discriminator Loss: 0.002627102793439917, Generator Loss: 5.264795780181885\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 93/100, Batch: 5/6, Discriminator Loss: 0.002577327469680313, Generator Loss: 5.283929824829102\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "Epoch: 94/100, Batch: 0/6, Discriminator Loss: 0.002526378168148824, Generator Loss: 5.303121089935303\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "Epoch: 94/100, Batch: 1/6, Discriminator Loss: 0.08549018623307347, Generator Loss: 5.234353065490723\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "Epoch: 94/100, Batch: 2/6, Discriminator Loss: 0.0026954860327350616, Generator Loss: 5.2321085929870605\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 94/100, Batch: 3/6, Discriminator Loss: 0.0026735130827546527, Generator Loss: 5.2464704513549805\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 94/100, Batch: 4/6, Discriminator Loss: 0.0026270676555668615, Generator Loss: 5.264893054962158\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 94/100, Batch: 5/6, Discriminator Loss: 0.0025768950379188027, Generator Loss: 5.284180641174316\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 95/100, Batch: 0/6, Discriminator Loss: 0.0025256152476362814, Generator Loss: 5.303522109985352\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 95/100, Batch: 1/6, Discriminator Loss: 0.08549651503562927, Generator Loss: 5.23419713973999\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Epoch: 95/100, Batch: 2/6, Discriminator Loss: 0.0026960619911733374, Generator Loss: 5.231934547424316\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 95/100, Batch: 3/6, Discriminator Loss: 0.002673844985793039, Generator Loss: 5.2464141845703125\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 95/100, Batch: 4/6, Discriminator Loss: 0.002627051432909866, Generator Loss: 5.264984607696533\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "Epoch: 95/100, Batch: 5/6, Discriminator Loss: 0.0025764795010445596, Generator Loss: 5.284425735473633\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Epoch: 96/100, Batch: 0/6, Discriminator Loss: 0.0025248665325943165, Generator Loss: 5.303918838500977\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Epoch: 96/100, Batch: 1/6, Discriminator Loss: 0.0855027912184596, Generator Loss: 5.234035491943359\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Epoch: 96/100, Batch: 2/6, Discriminator Loss: 0.0026966548304017124, Generator Loss: 5.231756210327148\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Epoch: 96/100, Batch: 3/6, Discriminator Loss: 0.0026741961760308186, Generator Loss: 5.246351718902588\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 96/100, Batch: 4/6, Discriminator Loss: 0.002627049088005151, Generator Loss: 5.265070915222168\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 96/100, Batch: 5/6, Discriminator Loss: 0.0025760794524103403, Generator Loss: 5.284665107727051\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 97/100, Batch: 0/6, Discriminator Loss: 0.002524128995657904, Generator Loss: 5.3043084144592285\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 97/100, Batch: 1/6, Discriminator Loss: 0.08550902851857245, Generator Loss: 5.23383903503418\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "Epoch: 97/100, Batch: 2/6, Discriminator Loss: 0.0026973514536621224, Generator Loss: 5.23153829574585\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "Epoch: 97/100, Batch: 3/6, Discriminator Loss: 0.0026746543194349215, Generator Loss: 5.2462544441223145\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "Epoch: 97/100, Batch: 4/6, Discriminator Loss: 0.00262714070322545, Generator Loss: 5.265127182006836\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Epoch: 97/100, Batch: 5/6, Discriminator Loss: 0.0025757569906090794, Generator Loss: 5.284879684448242\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "Epoch: 98/100, Batch: 0/6, Discriminator Loss: 0.002523454565810823, Generator Loss: 5.304679870605469\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 98/100, Batch: 1/6, Discriminator Loss: 0.08551495149731636, Generator Loss: 5.233665466308594\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Epoch: 98/100, Batch: 2/6, Discriminator Loss: 0.0026979702677181194, Generator Loss: 5.231350898742676\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Epoch: 98/100, Batch: 3/6, Discriminator Loss: 0.0026750301090032735, Generator Loss: 5.246185779571533\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Epoch: 98/100, Batch: 4/6, Discriminator Loss: 0.002627161547252399, Generator Loss: 5.265206336975098\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Epoch: 98/100, Batch: 5/6, Discriminator Loss: 0.0025753773322776397, Generator Loss: 5.285111904144287\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "Epoch: 99/100, Batch: 0/6, Discriminator Loss: 0.002522733100200014, Generator Loss: 5.305063724517822\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Epoch: 99/100, Batch: 1/6, Discriminator Loss: 0.08552117901854217, Generator Loss: 5.233430862426758\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Epoch: 99/100, Batch: 2/6, Discriminator Loss: 0.0026987831051883404, Generator Loss: 5.231093883514404\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Epoch: 99/100, Batch: 3/6, Discriminator Loss: 0.0026755934186439845, Generator Loss: 5.2460551261901855\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Epoch: 99/100, Batch: 4/6, Discriminator Loss: 0.0026273342318745563, Generator Loss: 5.265237808227539\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 99/100, Batch: 5/6, Discriminator Loss: 0.0025751155496891442, Generator Loss: 5.285309791564941\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "Epoch: 100/100, Batch: 0/6, Discriminator Loss: 0.002522093368536815, Generator Loss: 5.305426120758057\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Epoch: 100/100, Batch: 1/6, Discriminator Loss: 0.0855269730091095, Generator Loss: 5.233254432678223\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Epoch: 100/100, Batch: 2/6, Discriminator Loss: 0.002699408076182408, Generator Loss: 5.230905532836914\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 100/100, Batch: 3/6, Discriminator Loss: 0.002675976958926185, Generator Loss: 5.245985507965088\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Epoch: 100/100, Batch: 4/6, Discriminator Loss: 0.002627357965138799, Generator Loss: 5.265316963195801\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Epoch: 100/100, Batch: 5/6, Discriminator Loss: 0.002574738098587659, Generator Loss: 5.285542964935303\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Generator model\n",
        "generator = keras.Sequential([\n",
        "    layers.Dense(256, input_shape=(100,), activation='relu'),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dense(12288, activation='tanh'),  # Output layer with 12288 (3x64x64) units for a 64x64 RGB image\n",
        "])\n",
        "\n",
        "# Discriminator model\n",
        "discriminator = keras.Sequential([\n",
        "    layers.Dense(1024, input_shape=(12288,), activation='relu'),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid'),  # Output layer with a single unit for binary classification\n",
        "])\n",
        "\n",
        "# Combined model (GAN)\n",
        "gan = keras.Sequential([generator, discriminator])\n",
        "\n",
        "# Compile discriminator\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "# Compile GAN\n",
        "discriminator.trainable = False  # Freeze the discriminator during GAN training\n",
        "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "# Load real cat images dataset\n",
        "# ...\n",
        "\n",
        "# Training loop\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(len(flattened_images) // batch_size):\n",
        "        # Train discriminator\n",
        "        noise = np.random.normal(0, 1, size=(batch_size, 100))\n",
        "        fake_images = generator.predict(noise)\n",
        "        real_batch = flattened_images[batch * batch_size : (batch + 1) * batch_size]\n",
        "\n",
        "        # Labels for real and fake images\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_batch, labels_real)\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, labels_fake)\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "        # Train generator\n",
        "        noise = np.random.normal(0, 1, size=(batch_size, 100))\n",
        "        generator_loss = gan.train_on_batch(noise, labels_real)\n",
        "\n",
        "        # Print training progress\n",
        "        print(f\"Epoch: {epoch+1}/{epochs}, Batch: {batch}/{len(real_images) // batch_size}, \"\n",
        "              f\"Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n",
        "\n",
        "# Generate new cat images\n",
        "\n",
        "# Save generated cat images\n",
        "# ...\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = np.random.normal(0, 1, size=(400, 100))\n",
        "generated_images = generator.predict(noise)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTZ8aDA2oMh2",
        "outputId": "6a049dfd-574f-4740-a2da-347c911740ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 1s 70ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(generated_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qgdlCcKoTPT",
        "outputId": "c611a7cd-0bc0-4764-e690-fb1494f7f614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_images[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3f0hgHu35A4",
        "outputId": "fa8e0518-1993-481b-9442-7cdc72cfc30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.06682332, -0.05057115, -0.01398592, ..., -0.16630796,\n",
              "        0.12554696, -0.08610539], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_array=generated_images[1]"
      ],
      "metadata": {
        "id": "NiofOFqNZdHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image = np.reshape(image_array, (64, 64, 3))  # Reshape to (height, width, channels)\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wolL1o7kbxT8",
        "outputId": "351b46b1-8a3f-457b-ab7d-287c24f20679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_rgb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWai7xD1caLF",
        "outputId": "d0ff3376-60bd-4d3b-ac1b-df47205d101c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[121, 121, 121]],\n",
              "\n",
              "       [[123, 123, 123]],\n",
              "\n",
              "       [[112, 112, 112]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[132, 132, 132]],\n",
              "\n",
              "       [[131, 131, 131]],\n",
              "\n",
              "       [[132, 132, 132]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9EtE4AGjcvje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}